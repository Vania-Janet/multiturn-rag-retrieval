version: '3.8'

services:
  mtrag-retrieval:
    build:
      context: .
      dockerfile: Dockerfile
    image: mtrag-retrieval:latest
    container_name: mtrag-retrieval
    
    # GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Environment variables
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/workspace/cache
      - HUGGINGFACE_HUB_CACHE=/workspace/cache/huggingface
      - TRANSFORMERS_CACHE=/workspace/cache/transformers
      - COHERE_API_KEY=${COHERE_API_KEY}
      - VOYAGE_API_KEY=${VOYAGE_API_KEY}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    
    # Volume mounts
    volumes:
      - ./data:/workspace/mt-rag-benchmark/task_a_retrieval/data
      - ./experiments:/workspace/mt-rag-benchmark/task_a_retrieval/experiments
      - ./indices:/workspace/mt-rag-benchmark/task_a_retrieval/indices
      - ./logs:/workspace/mt-rag-benchmark/task_a_retrieval/logs
      - ./cache:/workspace/cache
      - ./.env:/workspace/mt-rag-benchmark/task_a_retrieval/.env:ro
    
    # Working directory
    working_dir: /workspace/mt-rag-benchmark/task_a_retrieval
    
    # Keep container running
    tty: true
    stdin_open: true
    
    # Shared memory size (important for PyTorch DataLoader)
    shm_size: '16gb'
    
    # Network
    networks:
      - mtrag-network

networks:
  mtrag-network:
    driver: bridge
