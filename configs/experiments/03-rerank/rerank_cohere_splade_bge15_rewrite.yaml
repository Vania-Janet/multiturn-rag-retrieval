# Reranking: SPLADE + BGE-base with Ground Truth Rewrites + Cohere Rerank-3.5
# For: CLOUD, FIQA (remaining domains)
# Expected: 0.42-0.44 nDCG@10 â†’ Potential +2-5% with Cohere

experiment:
  name: "rerank_cohere_splade_bge15_rewrite"
  type: "retrieval"
  description: "Hybrid SPLADE + BGE-base with RRF fusion, ground truth rewrites, and Cohere reranking"

data:
  domains: ["cloud", "fiqa"]
  query_mode: "rewrite"
  query_file: "data/retrieval_tasks/{domain}/{domain}_rewrite.jsonl"
  qrels_file: "data/retrieval_tasks/{domain}/qrels/dev.tsv"
  corpus_path: "data/passage_level_processed/{domain}"

retrieval:
  type: "hybrid"
  fusion_method: "rrf"  # Reciprocal Rank Fusion
  rrf_k: 60
  sparse:
    method: "splade"
    top_k: 300
  dense:
    method: "bge"
    model_name: "BAAI/bge-base-en-v1.5"
    top_k: 300

query_transform:
  enabled: false

reranking:
  enabled: true
  type: "cohere"
  model_name: "rerank-v4-pro"  # Cohere Rerank 4 Pro (latest, best performance)
  top_k_candidates: 100  # Rerank top 100 from fusion
  max_chunks_per_doc: 10

output:
  save_results: true
  results_dir: "experiments/{experiment_name}/{domain}"
  
metrics:
  compute: ["ndcg@5", "ndcg@10", "ndcg@20", "recall@5", "recall@10", "recall@20", "map@10", "precision@5"]
