experiment:
  name: "bm25_vllm_condensation_70b"
  description: "BM25 + VLLM Query Condensation (Llama 3.1 70B AWQ)"

retrieval:
  type: "sparse"
  method: "bm25"
  top_k: 300
  index_path: "indices/clapnq/bm25"

query_transform:
  enabled: true
  rewriter_type: "vllm"
  merge_strategy: "replace"
  rewriter_config:
    model_name: "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4"
    quantization: "awq"
    tensor_parallel_size: 2
    temperature: 0
    max_rewrites: 1
    max_tokens: 128
    gpu_memory_utilization: 0.90
    max_model_len: 8192

data:
  query_mode: "last_turn"
